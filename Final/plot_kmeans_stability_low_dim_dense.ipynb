{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Empirical evaluation of the impact of k-means initialization\n",
    "\n",
    "\n",
    "Evaluate the ability of k-means initializations strategies to make\n",
    "the algorithm convergence robust as measured by the relative standard\n",
    "deviation of the inertia of the clustering (i.e. the sum of squared\n",
    "distances to the nearest cluster center).\n",
    "\n",
    "The first plot shows the best inertia reached for each combination\n",
    "of the model (``KMeans`` or ``MiniBatchKMeans``) and the init method\n",
    "(``init=\"random\"`` or ``init=\"kmeans++\"``) for increasing values of the\n",
    "``n_init`` parameter that controls the number of initializations.\n",
    "\n",
    "The second plot demonstrate one single run of the ``MiniBatchKMeans``\n",
    "estimator using a ``init=\"random\"`` and ``n_init=1``. This run leads to\n",
    "a bad convergence (local optimum) with estimated centers stuck\n",
    "between ground truth clusters.\n",
    "\n",
    "The dataset used for evaluation is a 2D grid of isotropic Gaussian\n",
    "clusters widely spaced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Evaluation of KMeans with k-means++ init\n",
      "Evaluation of KMeans with random init\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a351a55db5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_init_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             km = factory(n_clusters=n_clusters, init=init, random_state=run_id,\n\u001b[0;32m---> 65\u001b[0;31m                          n_init=n_init, **params).fit(X)\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0minertia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_init_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialization complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     centers, labels, n_iter = k_means_elkan(X, n_clusters, centers, tol=tol,\n\u001b[0;32m--> 400\u001b[0;31m                                             max_iter=max_iter, verbose=verbose)\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0minertia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/cluster/_k_means_elkan.pyx\u001b[0m in \u001b[0;36msklearn.cluster._k_means_elkan.k_means_elkan\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mYY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \"\"\"Dot product that handle the sparse matrix case correctly\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f212d76f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "# Number of run (with randomly generated dataset) for each strategy so as\n",
    "# to be able to compute an estimate of the standard deviation\n",
    "n_runs = 5\n",
    "\n",
    "n_init_range = np.array([1, 5, 10, 15, 1000])\n",
    "\n",
    "n_samples_per_center = 100\n",
    "grid_size = 3\n",
    "scale = 0.1\n",
    "n_clusters = grid_size ** 2\n",
    "\n",
    "\n",
    "def make_data(random_state, n_samples_per_center, grid_size, scale):\n",
    "    random_state = check_random_state(random_state)\n",
    "    centers = np.array([[i, j]\n",
    "                        for i in range(grid_size)\n",
    "                        for j in range(grid_size)])\n",
    "    n_clusters_true, n_features = centers.shape\n",
    "\n",
    "    noise = random_state.normal(\n",
    "        scale=scale, size=(n_samples_per_center, centers.shape[1]))\n",
    "\n",
    "    X = np.concatenate([c + noise for c in centers])\n",
    "    y = np.concatenate([[i] * n_samples_per_center\n",
    "                        for i in range(n_clusters_true)])\n",
    "    return shuffle(X, y, random_state=random_state)\n",
    "\n",
    "# Part 1: Quantitative evaluation of various init methods\n",
    "\n",
    "plt.figure()\n",
    "plots = []\n",
    "legends = []\n",
    "\n",
    "cases = [\n",
    "    (KMeans, 'k-means++', {}),\n",
    "    (KMeans, 'random', {}),\n",
    "    (MiniBatchKMeans, 'k-means++', {'max_no_improvement': 3}),\n",
    "    (MiniBatchKMeans, 'random', {'max_no_improvement': 3, 'init_size': 500}),\n",
    "]\n",
    "\n",
    "for factory, init, params in cases:\n",
    "    print(\"Evaluation of %s with %s init\" % (factory.__name__, init))\n",
    "    inertia = np.empty((len(n_init_range), n_runs))\n",
    "\n",
    "    for run_id in range(n_runs):\n",
    "        X, y = make_data(run_id, n_samples_per_center, grid_size, scale)\n",
    "        for i, n_init in enumerate(n_init_range):\n",
    "            km = factory(n_clusters=n_clusters, init=init, random_state=run_id,\n",
    "                         n_init=n_init, **params).fit(X)\n",
    "            inertia[i, run_id] = km.inertia_\n",
    "    p = plt.errorbar(n_init_range, inertia.mean(axis=1), inertia.std(axis=1))\n",
    "    plots.append(p[0])\n",
    "    legends.append(\"%s with %s init\" % (factory.__name__, init))\n",
    "\n",
    "plt.xlabel('n_init')\n",
    "plt.ylabel('inertia')\n",
    "plt.legend(plots, legends)\n",
    "plt.title(\"Mean inertia for various k-means init across %d runs\" % n_runs)\n",
    "\n",
    "# Part 2: Qualitative visual inspection of the convergence\n",
    "\n",
    "X, y = make_data(random_state, n_samples_per_center, grid_size, scale)\n",
    "km = MiniBatchKMeans(n_clusters=n_clusters, init='random', n_init=1,\n",
    "                     random_state=random_state).fit(X)\n",
    "\n",
    "plt.figure()\n",
    "for k in range(n_clusters):\n",
    "    my_members = km.labels_ == k\n",
    "    color = cm.nipy_spectral(float(k) / n_clusters, 1)\n",
    "    plt.plot(X[my_members, 0], X[my_members, 1], 'o', marker='.', c=color)\n",
    "    cluster_center = km.cluster_centers_[k]\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o',\n",
    "             markerfacecolor=color, markeredgecolor='k', markersize=6)\n",
    "    plt.title(\"Example cluster allocation with a single random init\\n\"\n",
    "              \"with MiniBatchKMeans\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
